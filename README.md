# 🧠 AI Compliance Learning Journey — Fábio Everton

> **Strategic AI Engineering Pathway: Focused on Security, Governance & Regulatory Compliance**

This repository serves as my **central hub for AI, Security, and Governance projects**, as well as a **living technical roadmap** — tracking my immersion in 44 strategically selected certifications and courses. The goal is to master applied AI engineering with emphasis on **secure-by-design architectures, compliance alignment, explainability, DevSecOps pipelines, and audit-ready systems**.

---

## 🎯 Why This Journey?

In a rapidly evolving AI landscape, the demand for **secure, ethical, and auditable systems** is non-negotiable. This journey targets advanced, production-ready skills across:

* **🔐 Security & DevSecOps for AI** — Evidence-based, Zero Trust principles across LLM and ML pipelines.
* **🧠 LLMOps & Agent Engineering** — LangChain, RAG pipelines, autonomous agent orchestration.
* **🧭 AI Governance & Global Compliance** — ISO/IEC 42001, NIST AI RMF, GDPR, and aligned risk controls.
* **⚖️ Responsible AI & Trust** — Explainability (XAI), bias mitigation, ethical frameworks, reproducibility.
* **🔒 Post-Quantum Cryptography & Data Resilience** — Future-proofing AI systems with PQC.
* **📊 Observability & Automated AI Workflows** — Secure, observable, and maintainable AI pipelines.

---

## 🗂 Structure & Navigation

The repository is structured by **technical domains (pillars)**, each containing subfolders with practical assets, certificates, Git-based deliverables, and applied case studies.

| Pillar                      | Area of Focus                 | Description                                                   |
| :-------------------------- | :---------------------------- | :------------------------------------------------------------ |
| **Security & DevSecOps**    | Secure pipelines, DSOMM, PQC  | OWASP LLM, threat mitigation, GitHub Security, Zero Trust.    |
| **Governance & Compliance** | Frameworks, audits, risk      | ISO 42001, GDPR, NIST AI RMF, AIGP, COBIT, ITIL.              |
| **LLMs & LangChain**        | LLMOps, RAG, vector DBs       | LangChain, GenAI, prompt design, RAG engineering.             |
| **Ethics & Explainability** | Responsible AI, fairness, XAI | AI alignment, AI safety, explainability, fairness in finance. |
| **Finance & Applied AI**    | Quantitative modeling         | Forecasting, derivatives, AI+XGBoost, WQU projects.           |
| **Leadership & Product**    | Strategic execution           | MIT AI Strategy, YC Startup School, GTM with AI security.     |

---

## 🏅 Completed Certifications & Programs

All items below are completed and verifiable. Deliverables and project evidence are organized in corresponding Git folders.

### 🔐 Security & DevSecOps

* GenAI Security (OWASP LLM Top 10)
* LLM Security Patterns — Microsoft Threat Matrix
* OWASP DevSecOps Maturity Model (DSOMM)
* Secure MLOps — Udacity / DeepLearning.ai
* GitHub Actions + Semgrep / Trivy / Checkov
* GitHub Advanced Security (CodeQL, Dependabot)
* Post-Quantum Cryptography for AI Pipelines
* Zero Trust Architecture for AI Inference
* MIT AI Strategy (Security/Leadership)
* CIPP/E — IAPP (Data Privacy & API Risk)

### 🧭 Governance & Compliance

* AI Compliance — GDPR + ISO/IEC 42001
* ISO/IEC 42001 + 27701 Auditing
* NIST AI RMF + SP 800-53
* ICA AI for Compliance Professionals
* ISACA AIGP / IAPP AIGP
* COBIT 2019 Foundation
* ITIL 4 Foundation
* GNAI — Oxford + GovAI
* MIT AI Policy — CSAIL + Sloan

### 🧠 LLMs, LangChain & RAG Engineering

* IBM Generative AI Engineering — Coursera
* LangChain Full Stack (Firebase, Vercel)
* RAG & LangChain — DeepLearning.ai
* Prompt Engineering — DeepLearning.ai
* Multi-document RAG Pipelines
* AI for Quantitative Finance — WQU

### ⚖️ Ethics, Fairness & Explainability

* Explainable AI — Google Cloud
* Responsible AI — Microsoft Learn
* Responsible AI in Financial Systems — FCA
* Ethics in AI — DeepLearning.ai, IBM, Google
* OECD/UNESCO — Responsible AI Principles
* Stanford HAI — Future of Human-Centered AI
* DeepMind — AI Safety & Alignment Bootcamp
* Fairness & Reproducibility — arXiv, SSRN Publication

### 💼 Leadership & Product Strategy

* MIT AI Strategy for Executives
* Y Combinator — Startup School
* WQU — AI Product Thinking for Finance

### 💹 Finance & Applied AI

* AI for Quantitative Finance — WQU
* Revenue Forecasting with Explainability (Custom Project)

---

## 📁 Git Repository Organization

Every listed certification is linked to a subfolder containing:

* Source notes, reports and compliance analysis.
* Jupyter notebooks or LangChain pipelines.
* Automation and DevSecOps implementation.
* JSON audit logs or SBOMs when applicable.

🧠 Live examples:

* [`llmops/ibm-generative-ai-engineering`](https://github.com/fabiobeverton/ai-compliance-learning-journey/tree/main/llmops/ibm-generative-ai-engineering)
* [`security/github-actions-semgrep-trivy-checkov`](https://github.com/fabiobeverton/ai-compliance-learning-journey/tree/main/security/github-actions-semgrep-trivy-checkov)
* [`governance/nist-ai-rmf`](https://github.com/fabiobeverton/ai-compliance-learning-journey/tree/main/governance/nist-ai-rmf)
* [`explainability/xai-google`](https://github.com/fabiobeverton/ai-compliance-learning-journey/tree/main/explainability/xai-google)

---

## 👤 About Me

**Fábio Everton**
Founder @BRACHAT | AI Security Engineer in Progress | MSc Financial Engineering (WQU)

I bring 10+ years of experience as an executive in operations, transitioning with full force into **AI Security, LLMOps, and Strategic Governance**. I design and build AI solutions with strong emphasis on compliance, resilience, and traceability.

> "Audit-first, AI-driven execution. Traceable, secure, and built to scale."

---

## 🔗 Useful Links

* 🔗 [GitHub Repository with Certifications](https://github.com/Fabiobeverton/Fabiobeverton-ai-compliance-learning-journey)
* 🧠 [Live Showcase Page](https://fabiobeverton.github.io/everton-showcase/)
* 💼 [LinkedIn: Fabio Everton](https://www.linkedin.com/in/fabio-everton-3b62b1129/)
* 📧 [fabio@brachat.com.br](mailto:fabio@brachat.com.br)
